{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Citation Recommendation on Scholarly Legal Articles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BM-25 + Fine-tuned LegalBERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:28:15.099155Z",
     "end_time": "2023-06-13T08:28:16.477660Z"
    }
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Plus\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('/Users/dgknrsln/Documents/pythonProject/EXPERIMENTS/LATEST_test_docs.pkl', 'rb') as f:\n",
    "    docs = pickle.load(f)\n",
    "\n",
    "with open('/Users/dgknrsln/Documents/pythonProject/EXPERIMENTS/LATEST_test_queries.pkl', 'rb') as f:\n",
    "    queries = pickle.load(f)\n",
    "\n",
    "with open('/Users/dgknrsln/Documents/pythonProject/EXPERIMENTS/LATEST_test_data.pkl', 'rb') as f:\n",
    "    pair = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:28:16.479164Z",
     "end_time": "2023-06-13T08:28:16.503094Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open('/Users/dgknrsln/Documents/pythonProject/EXPERIMENTS/LATEST/LATEST_legalbert_inference_docs.pkl', 'rb') as f:\n",
    "    parent_embeddings_list = pickle.load(f)\n",
    "\n",
    "with open('/Users/dgknrsln/Documents/pythonProject/EXPERIMENTS/LATEST/LATEST_legalbert_inference_queries.pkl', 'rb') as f:\n",
    "    child_embeddings_list = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:28:16.504260Z",
     "end_time": "2023-06-13T08:28:16.526430Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tokenized_corpus = [doc.split() for doc in list(set(docs))]\n",
    "\n",
    "bm25 = BM25Plus(tokenized_corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:28:16.557658Z",
     "end_time": "2023-06-13T08:28:16.640221Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. MAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2675/2675 [02:24<00:00, 18.52it/s]\n"
     ]
    }
   ],
   "source": [
    "total_prec = 0\n",
    "found = 0\n",
    "for i in tqdm(range(len(queries))):\n",
    "\n",
    "    sample = queries[i]\n",
    "    tokenized_query = sample.split()\n",
    "    results = bm25.get_top_n(tokenized_query, tokenized_corpus, n=10)\n",
    "\n",
    "    result_emb = []\n",
    "\n",
    "    for x in results:\n",
    "        result_emb.append(parent_embeddings_list[docs.index(' '.join(str(e) for e in x))])\n",
    "\n",
    "    cos_matrix = pairwise.cosine_similarity(child_embeddings_list[i].reshape(1, -1), result_emb)\n",
    "    retrieved = list(sorted(enumerate(cos_matrix[0]), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    count = 0\n",
    "    precision = 0\n",
    "    index = 0\n",
    "    for m in retrieved:\n",
    "        if ' '.join(str(e) for e in results[m[0]]) in pair[i][1]:\n",
    "            count += 1\n",
    "            precision += count/(index+1)\n",
    "        index += 1\n",
    "\n",
    "    if count == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        found += 1\n",
    "        precision /= count\n",
    "\n",
    "    total_prec += precision"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:28:16.644697Z",
     "end_time": "2023-06-13T08:30:41.087262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19641032487761426\n"
     ]
    }
   ],
   "source": [
    "MAP = total_prec / len(queries)\n",
    "print(MAP)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:30:41.088676Z",
     "end_time": "2023-06-13T08:30:41.090671Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2675/2675 [02:25<00:00, 18.33it/s]\n"
     ]
    }
   ],
   "source": [
    "total_prec = 0\n",
    "found = 0\n",
    "for i in tqdm(range(len(queries))):\n",
    "\n",
    "    sample = queries[i]\n",
    "    tokenized_query = sample.split()\n",
    "    results = bm25.get_top_n(tokenized_query, tokenized_corpus, n=10)\n",
    "\n",
    "    result_emb = []\n",
    "\n",
    "    for x in results:\n",
    "        result_emb.append(parent_embeddings_list[docs.index(' '.join(str(e) for e in x))])\n",
    "\n",
    "    cos_matrix = pairwise.cosine_similarity(child_embeddings_list[i].reshape(1, -1), result_emb)\n",
    "    retrieved = list(sorted(enumerate(cos_matrix[0]), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    count = 0\n",
    "    for m in retrieved:\n",
    "        if ' '.join(str(e) for e in results[m[0]]) in pair[i][1]:\n",
    "            count += 1\n",
    "\n",
    "    total_prec += (count / len(pair[i][1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:30:41.094246Z",
     "end_time": "2023-06-13T08:33:07.058160Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4520778816199377\n"
     ]
    }
   ],
   "source": [
    "RECALL = total_prec / len(queries)\n",
    "print(RECALL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:33:07.059387Z",
     "end_time": "2023-06-13T08:33:07.061159Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. MRR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2675/2675 [02:25<00:00, 18.44it/s]\n"
     ]
    }
   ],
   "source": [
    "total_prec = 0\n",
    "found = 0\n",
    "for i in tqdm(range(len(queries))):\n",
    "\n",
    "    sample = queries[i]\n",
    "    tokenized_query = sample.split()\n",
    "    results = bm25.get_top_n(tokenized_query, tokenized_corpus, n=10)\n",
    "\n",
    "    result_emb = []\n",
    "\n",
    "    for x in results:\n",
    "        result_emb.append(parent_embeddings_list[docs.index(' '.join(str(e) for e in x))])\n",
    "\n",
    "    cos_matrix = pairwise.cosine_similarity(child_embeddings_list[i].reshape(1, -1), result_emb)\n",
    "    retrieved = list(sorted(enumerate(cos_matrix[0]), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    index = 1\n",
    "    for m in retrieved:\n",
    "        if ' '.join(str(e) for e in results[m[0]]) in pair[i][1]:\n",
    "            break\n",
    "        index += 1\n",
    "\n",
    "    total_prec += (1/index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:33:07.064230Z",
     "end_time": "2023-06-13T08:35:32.100075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2460885760138089\n"
     ]
    }
   ],
   "source": [
    "MRR = total_prec / len(queries)\n",
    "print(MRR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:35:32.100998Z",
     "end_time": "2023-06-13T08:35:32.103146Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.19641032487761426\n",
      "Recall@10: 0.4520778816199377\n",
      "MRR@10: 0.2460885760138089\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP@10: \" + str(MAP))\n",
    "print(\"Recall@10: \" + str(RECALL))\n",
    "print(\"MRR@10: \" + str(MRR))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T08:35:32.104384Z",
     "end_time": "2023-06-13T08:35:32.106235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "legaltuned",
   "language": "python",
   "display_name": "legaltuned"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
