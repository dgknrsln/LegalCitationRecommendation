Social software has a power problem.1  Actually, it has two. The first is technical.  Unlike the rule of law, the rule of software is simple and brutal: whoever controls the software makes the rules.  And if power corrupts, then automatic power corrupts automatically.  Facebook can drop you down the memory hole; Pay-Pal can garnish your pay.  These sovereigns of software have absolute and dictatorial control over their domains. 

Is it possible to create online spaces without technical power?  It is not, because of social software’s second power problem.  Behind technical power, there is also social power.  When-ever people come together through software, they must agree which software they will use.  That agreement vests technical power in whoever controls the software.  Social software cannot be completely free of coercion—not without ceasing to be social, or ceasing to be software. 

Rule-of-law values are worth defending in the age of soft-ware empires, but they cannot be fully embedded in software it-self.  Any technical design can always be changed through an exercise of social power.  Software can help by making this coercion more obvious, or by requiring more people to join together in it, but software alone cannot fully protect users.  Whatever limits make social software humane, free, and fair will have to come from somewhere else—they will have to come from We the Users.

Published: 35 Pace Law Review 135 (2105)