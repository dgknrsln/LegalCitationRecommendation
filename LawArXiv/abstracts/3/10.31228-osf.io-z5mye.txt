CITE AS: M. Canellas and R. Haga, "Lost in Translation: Building a Common Language for Regulating Autonomous Weapons," in IEEE Technology and Society Magazine, vol. 35, no. 3, pp. 50-58, Sept. 2016. doi: 10.1109/MTS.2016.2593218

There have been three UN meetings of experts in 2014, 2015, and 2016 to address autonomous weapons systems (AWS), however, little to no progress. In this article, we argue that the fundamental reason for the stalled discussions is the lack of a unifying, technical language for describing and understanding the problems posed by AWS. A unifying, technical language would address two major communications issues facing the discussants of AWS: an inability to identify the sources of the conflict and solutions that have consensus, and an inability to operationalize the regulations that are agreed upon. We propose that the language of cognitive systems engineering can be the unifying technical language to provide initial answers to the four key questions at the UN: (1) How do we define autonomy? Use the requirements for effective function allocation to develop standards for human-AWS interaction and meaningful human control. (2) What amount or quality of human control necessary for lawful use of AWS? Use function allocation’s models and metrics to evaluate human-AWS interaction and enforce meaningful human control standards. (3) What would an accountability framework look like for AWS? Use the models and metrics for evaluating authority-responsibility mismatches in function allocation to address the AWS responsibility gap. (4) How do we review and certify permissible AWS? Use the human-automation issues that have been explored and addressed by function allocation to develop case studies and technical standards for human-AWS interaction.